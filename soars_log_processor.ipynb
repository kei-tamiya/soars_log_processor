{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import codecs\n",
    "import xlwt\n",
    "import os.path\n",
    "import openpyxl as px\n",
    "import string\n",
    "import glob\n",
    "from openpyxl.styles import Border, Side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new_cols. 10\n",
      "new_cols. 0\n",
      "new_cols. 10\n",
      "new_cols. 0\n",
      "new_cols. 10\n",
      "new_cols. 0\n",
      "new_cols. 10\n",
      "new_cols. 0\n",
      "new_cols. 10\n",
      "new_cols. 0\n",
      "new_cols. 10\n",
      "new_cols. 0\n",
      "new_cols. 10\n",
      "new_cols. 0\n",
      "new_cols. 10\n",
      "new_cols. 0\n",
      "new_cols. 10\n",
      "new_cols. 0\n",
      "new_cols. 10\n",
      "new_cols. 0\n",
      "new_cols. 10\n",
      "new_cols. 0\n",
      "new_cols. 10\n",
      "new_cols. 0\n",
      "new_cols. 10\n",
      "new_cols. 0\n",
      "new_cols. 10\n",
      "new_cols. 0\n",
      "new_cols. 10\n",
      "new_cols. 0\n",
      "new_cols. 10\n",
      "new_cols. 0\n",
      "new_cols. 10\n",
      "new_cols. 0\n",
      "new_cols. 10\n",
      "new_cols. 0\n",
      "new_cols. 10\n",
      "new_cols. 0\n",
      "new_cols. 10\n",
      "new_cols. 0\n",
      "new_cols. 10\n",
      "new_cols. 0\n",
      "new_cols. 10\n",
      "new_cols. 0\n",
      "new_cols. 10\n",
      "new_cols. 0\n",
      "new_cols. 10\n",
      "new_cols. 0\n",
      "new_cols. 10\n",
      "new_cols. 0\n",
      "new_cols. 20\n",
      "new_cols. 0\n",
      "new_cols. 20\n",
      "new_cols. 0\n",
      "new_cols. 20\n",
      "new_cols. 0\n",
      "new_cols. 20\n",
      "new_cols. 0\n",
      "new_cols. 20\n",
      "new_cols. 0\n",
      "new_cols. 20\n",
      "new_cols. 0\n",
      "new_cols. 20\n",
      "new_cols. 0\n",
      "new_cols. 20\n",
      "new_cols. 0\n",
      "new_cols. 20\n",
      "new_cols. 0\n",
      "new_cols. 20\n",
      "new_cols. 0\n",
      "new_cols. 20\n",
      "new_cols. 0\n",
      "new_cols. 20\n",
      "new_cols. 0\n",
      "new_cols. 20\n",
      "new_cols. 0\n",
      "new_cols. 20\n",
      "new_cols. 0\n",
      "new_cols. 20\n",
      "new_cols. 0\n",
      "new_cols. 20\n",
      "new_cols. 0\n",
      "new_cols. 20\n",
      "new_cols. 0\n",
      "new_cols. 20\n",
      "new_cols. 0\n",
      "new_cols. 20\n",
      "new_cols. 0\n",
      "new_cols. 20\n",
      "new_cols. 0\n",
      "new_cols. 20\n",
      "new_cols. 0\n",
      "new_cols. 20\n",
      "new_cols. 0\n",
      "new_cols. 20\n",
      "new_cols. 0\n",
      "new_cols. 20\n",
      "new_cols. 0\n",
      "new_cols. 20\n",
      "new_cols. 0\n",
      "new_cols. 20\n",
      "new_cols. 0\n",
      "new_cols. 20\n",
      "new_cols. 0\n",
      "new_cols. 30\n",
      "new_cols. 0\n",
      "new_cols. 30\n",
      "new_cols. 0\n",
      "new_cols. 30\n",
      "new_cols. 0\n",
      "new_cols. 30\n",
      "new_cols. 0\n",
      "new_cols. 30\n",
      "new_cols. 0\n",
      "new_cols. 30\n",
      "new_cols. 0\n",
      "new_cols. 30\n",
      "new_cols. 0\n",
      "new_cols. 30\n",
      "new_cols. 0\n",
      "new_cols. 30\n",
      "new_cols. 0\n",
      "new_cols. 30\n",
      "new_cols. 0\n",
      "new_cols. 30\n",
      "new_cols. 0\n",
      "new_cols. 30\n",
      "new_cols. 0\n",
      "new_cols. 30\n",
      "new_cols. 0\n",
      "new_cols. 30\n",
      "new_cols. 0\n",
      "new_cols. 30\n",
      "new_cols. 0\n",
      "new_cols. 30\n",
      "new_cols. 0\n",
      "new_cols. 30\n",
      "new_cols. 0\n",
      "new_cols. 30\n",
      "new_cols. 0\n",
      "new_cols. 30\n",
      "new_cols. 0\n",
      "new_cols. 30\n",
      "new_cols. 0\n",
      "new_cols. 30\n",
      "new_cols. 0\n",
      "new_cols. 30\n",
      "new_cols. 0\n",
      "new_cols. 30\n",
      "new_cols. 0\n",
      "new_cols. 30\n",
      "new_cols. 0\n",
      "new_cols. 30\n",
      "new_cols. 0\n",
      "new_cols. 30\n",
      "new_cols. 0\n",
      "new_cols. 30\n",
      "new_cols. 0\n",
      "new_cols. 30\n",
      "new_cols. 0\n",
      "new_cols. 40\n",
      "new_cols. 0\n",
      "new_cols. 40\n",
      "new_cols. 0\n",
      "new_cols. 40\n",
      "new_cols. 0\n",
      "new_cols. 40\n",
      "new_cols. 0\n",
      "new_cols. 40\n",
      "new_cols. 0\n",
      "new_cols. 40\n",
      "new_cols. 0\n",
      "new_cols. 40\n",
      "new_cols. 0\n",
      "new_cols. 40\n",
      "new_cols. 0\n",
      "new_cols. 40\n",
      "new_cols. 0\n",
      "new_cols. 40\n",
      "new_cols. 0\n",
      "new_cols. 40\n",
      "new_cols. 0\n",
      "new_cols. 40\n",
      "new_cols. 0\n",
      "new_cols. 40\n",
      "new_cols. 0\n",
      "new_cols. 40\n",
      "new_cols. 0\n",
      "new_cols. 40\n",
      "new_cols. 0\n",
      "new_cols. 40\n",
      "new_cols. 0\n",
      "new_cols. 40\n",
      "new_cols. 0\n",
      "new_cols. 40\n",
      "new_cols. 0\n",
      "new_cols. 40\n",
      "new_cols. 0\n",
      "new_cols. 40\n",
      "new_cols. 0\n",
      "new_cols. 40\n",
      "new_cols. 0\n",
      "new_cols. 40\n",
      "new_cols. 0\n",
      "new_cols. 40\n",
      "new_cols. 0\n",
      "new_cols. 40\n",
      "new_cols. 0\n",
      "new_cols. 40\n",
      "new_cols. 0\n",
      "new_cols. 40\n",
      "new_cols. 0\n",
      "new_cols. 40\n",
      "new_cols. 0\n",
      "new_cols. 40\n",
      "new_cols. 0\n",
      "new_cols. 40\n",
      "new_cols. 0\n",
      "new_cols. 40\n",
      "new_cols. 0\n",
      "new_cols. 40\n",
      "new_cols. 0\n",
      "new_cols. 40\n",
      "new_cols. 0\n",
      "new_cols. 50\n",
      "new_cols. 0\n",
      "new_cols. 50\n",
      "new_cols. 0\n",
      "new_cols. 50\n",
      "new_cols. 0\n",
      "new_cols. 50\n",
      "new_cols. 0\n",
      "new_cols. 50\n",
      "new_cols. 0\n",
      "new_cols. 50\n",
      "new_cols. 0\n",
      "new_cols. 50\n",
      "new_cols. 0\n",
      "new_cols. 50\n",
      "new_cols. 0\n",
      "new_cols. 50\n",
      "new_cols. 0\n",
      "new_cols. 50\n",
      "new_cols. 0\n",
      "new_cols. 50\n",
      "new_cols. 0\n",
      "new_cols. 50\n",
      "new_cols. 0\n",
      "new_cols. 50\n",
      "new_cols. 0\n",
      "new_cols. 50\n",
      "new_cols. 0\n",
      "new_cols. 50\n",
      "new_cols. 0\n",
      "new_cols. 50\n",
      "new_cols. 0\n",
      "new_cols. 50\n",
      "new_cols. 0\n",
      "new_cols. 50\n",
      "new_cols. 0\n",
      "new_cols. 50\n",
      "new_cols. 0\n",
      "new_cols. 50\n",
      "new_cols. 0\n",
      "new_cols. 50\n",
      "new_cols. 0\n",
      "new_cols. 50\n",
      "new_cols. 0\n",
      "new_cols. 50\n",
      "new_cols. 0\n",
      "new_cols. 50\n",
      "new_cols. 0\n",
      "new_cols. 50\n",
      "new_cols. 0\n",
      "new_cols. 50\n",
      "new_cols. 0\n",
      "new_cols. 50\n",
      "new_cols. 0\n",
      "new_cols. 50\n",
      "new_cols. 0\n",
      "new_cols. 60\n",
      "new_cols. 0\n",
      "new_cols. 60\n",
      "new_cols. 0\n",
      "new_cols. 60\n",
      "new_cols. 0\n",
      "new_cols. 60\n",
      "new_cols. 0\n",
      "new_cols. 60\n",
      "new_cols. 0\n",
      "new_cols. 60\n",
      "new_cols. 0\n",
      "new_cols. 60\n",
      "new_cols. 0\n",
      "new_cols. 60\n",
      "new_cols. 0\n",
      "new_cols. 60\n",
      "new_cols. 0\n",
      "new_cols. 60\n",
      "new_cols. 0\n",
      "new_cols. 60\n",
      "new_cols. 0\n",
      "new_cols. 60\n",
      "new_cols. 0\n",
      "new_cols. 60\n",
      "new_cols. 0\n",
      "new_cols. 60\n",
      "new_cols. 0\n",
      "new_cols. 60\n",
      "new_cols. 0\n",
      "new_cols. 60\n",
      "new_cols. 0\n",
      "new_cols. 60\n",
      "new_cols. 0\n",
      "new_cols. 60\n",
      "new_cols. 0\n",
      "new_cols. 60\n",
      "new_cols. 0\n",
      "new_cols. 60\n",
      "new_cols. 0\n",
      "new_cols. 60\n",
      "new_cols. 0\n",
      "new_cols. 60\n",
      "new_cols. 0\n",
      "new_cols. 60\n",
      "new_cols. 0\n",
      "new_cols. 60\n",
      "new_cols. 0\n",
      "new_cols. 60\n",
      "new_cols. 0\n",
      "new_cols. 60\n",
      "new_cols. 0\n",
      "new_cols. 60\n",
      "new_cols. 0\n",
      "new_cols. 60\n",
      "new_cols. 0\n",
      "new_cols. 60\n",
      "new_cols. 0\n",
      "new_cols. 60\n",
      "new_cols. 0\n",
      "new_cols. 60\n",
      "new_cols. 0\n",
      "new_cols. 60\n",
      "new_cols. 0\n",
      "new_cols. 60\n",
      "new_cols. 0\n",
      "new_cols. 60\n",
      "new_cols. 0\n",
      "new_cols. 60\n",
      "new_cols. 0\n",
      "new_cols. 60\n",
      "new_cols. 0\n",
      "new_cols. 70\n",
      "new_cols. 0\n",
      "new_cols. 70\n",
      "new_cols. 0\n",
      "new_cols. 70\n",
      "new_cols. 0\n",
      "new_cols. 70\n",
      "new_cols. 0\n",
      "new_cols. 70\n",
      "new_cols. 0\n",
      "new_cols. 70\n",
      "new_cols. 0\n",
      "new_cols. 70\n",
      "new_cols. 0\n",
      "new_cols. 70\n",
      "new_cols. 0\n",
      "new_cols. 70\n",
      "new_cols. 0\n",
      "new_cols. 70\n",
      "new_cols. 0\n",
      "new_cols. 70\n",
      "new_cols. 0\n",
      "new_cols. 70\n",
      "new_cols. 0\n",
      "new_cols. 70\n",
      "new_cols. 0\n",
      "new_cols. 70\n",
      "new_cols. 0\n",
      "new_cols. 70\n",
      "new_cols. 0\n",
      "new_cols. 70\n",
      "new_cols. 0\n",
      "new_cols. 70\n",
      "new_cols. 0\n",
      "new_cols. 70\n",
      "new_cols. 0\n",
      "new_cols. 70\n",
      "new_cols. 0\n",
      "new_cols. 70\n",
      "new_cols. 0\n",
      "new_cols. 70\n",
      "new_cols. 0\n",
      "new_cols. 70\n",
      "new_cols. 0\n",
      "new_cols. 70\n",
      "new_cols. 0\n",
      "new_cols. 70\n",
      "new_cols. 0\n",
      "new_cols. 70\n",
      "new_cols. 0\n",
      "new_cols. 70\n",
      "new_cols. 0\n",
      "new_cols. 70\n",
      "new_cols. 0\n",
      "new_cols. 70\n",
      "new_cols. 0\n",
      "new_cols. 80\n",
      "new_cols. 0\n",
      "new_cols. 80\n",
      "new_cols. 0\n",
      "new_cols. 80\n",
      "new_cols. 0\n",
      "new_cols. 80\n",
      "new_cols. 0\n",
      "new_cols. 80\n",
      "new_cols. 0\n",
      "new_cols. 80\n",
      "new_cols. 0\n",
      "new_cols. 80\n",
      "new_cols. 0\n",
      "new_cols. 80\n",
      "new_cols. 0\n",
      "new_cols. 80\n",
      "new_cols. 0\n",
      "new_cols. 80\n",
      "new_cols. 0\n",
      "new_cols. 80\n",
      "new_cols. 0\n",
      "new_cols. 80\n",
      "new_cols. 0\n",
      "new_cols. 80\n",
      "new_cols. 0\n",
      "new_cols. 80\n",
      "new_cols. 0\n",
      "new_cols. 80\n",
      "new_cols. 0\n",
      "new_cols. 80\n",
      "new_cols. 0\n",
      "new_cols. 80\n",
      "new_cols. 0\n",
      "new_cols. 80\n",
      "new_cols. 0\n",
      "new_cols. 80\n",
      "new_cols. 0\n",
      "new_cols. 80\n",
      "new_cols. 0\n",
      "new_cols. 80\n",
      "new_cols. 0\n",
      "new_cols. 80\n",
      "new_cols. 0\n",
      "new_cols. 80\n",
      "new_cols. 0\n",
      "new_cols. 80\n",
      "new_cols. 0\n",
      "new_cols. 80\n",
      "new_cols. 0\n",
      "new_cols. 80\n",
      "new_cols. 0\n",
      "new_cols. 80\n",
      "new_cols. 0\n",
      "new_cols. 80\n",
      "new_cols. 0\n",
      "new_cols. 80\n",
      "new_cols. 0\n",
      "new_cols. 80\n",
      "new_cols. 0\n",
      "new_cols. 80\n",
      "new_cols. 0\n",
      "new_cols. 80\n",
      "new_cols. 0\n",
      "new_cols. 80\n",
      "new_cols. 0\n",
      "new_cols. 90\n",
      "new_cols. 0\n",
      "new_cols. 90\n",
      "new_cols. 0\n",
      "new_cols. 90\n",
      "new_cols. 0\n",
      "new_cols. 90\n",
      "new_cols. 0\n",
      "new_cols. 90\n",
      "new_cols. 0\n",
      "new_cols. 90\n",
      "new_cols. 0\n",
      "new_cols. 90\n",
      "new_cols. 0\n",
      "new_cols. 90\n",
      "new_cols. 0\n",
      "new_cols. 90\n",
      "new_cols. 0\n",
      "new_cols. 90\n",
      "new_cols. 0\n",
      "new_cols. 90\n",
      "new_cols. 0\n",
      "new_cols. 90\n",
      "new_cols. 0\n",
      "new_cols. 90\n",
      "new_cols. 0\n",
      "new_cols. 90\n",
      "new_cols. 0\n",
      "new_cols. 90\n",
      "new_cols. 0\n",
      "new_cols. 90\n",
      "new_cols. 0\n",
      "new_cols. 90\n",
      "new_cols. 0\n",
      "new_cols. 90\n",
      "new_cols. 0\n",
      "new_cols. 90\n",
      "new_cols. 0\n",
      "new_cols. 90\n",
      "new_cols. 0\n",
      "new_cols. 90\n",
      "new_cols. 0\n",
      "new_cols. 90\n",
      "new_cols. 0\n",
      "new_cols. 90\n",
      "new_cols. 0\n",
      "new_cols. 90\n",
      "new_cols. 0\n",
      "new_cols. 90\n",
      "new_cols. 0\n",
      "new_cols. 90\n",
      "new_cols. 0\n",
      "new_cols. 90\n",
      "new_cols. 0\n",
      "new_cols. 90\n",
      "new_cols. 0\n",
      "new_cols. 90\n",
      "new_cols. 0\n",
      "new_cols. 90\n",
      "new_cols. 0\n",
      "new_cols. 90\n",
      "new_cols. 0\n",
      "new_cols. 90\n",
      "new_cols. 0\n",
      "new_cols. 90\n",
      "new_cols. 0\n",
      "new_cols. 90\n",
      "new_cols. 0\n",
      "new_cols. 90\n",
      "new_cols. 0\n",
      "new_cols. 90\n",
      "new_cols. 0\n",
      "new_cols. 90\n",
      "new_cols. 0\n",
      "new_cols. 100\n",
      "new_cols. 0\n",
      "new_cols. 100\n",
      "new_cols. 0\n",
      "new_cols. 100\n",
      "new_cols. 0\n",
      "new_cols. 100\n",
      "new_cols. 0\n",
      "new_cols. 100\n",
      "new_cols. 0\n",
      "new_cols. 100\n",
      "new_cols. 0\n",
      "new_cols. 100\n",
      "new_cols. 0\n",
      "new_cols. 100\n",
      "new_cols. 0\n",
      "new_cols. 100\n",
      "new_cols. 0\n",
      "new_cols. 100\n",
      "new_cols. 0\n",
      "new_cols. 100\n",
      "new_cols. 0\n",
      "new_cols. 100\n",
      "new_cols. 0\n",
      "new_cols. 100\n",
      "new_cols. 0\n",
      "new_cols. 100\n",
      "new_cols. 0\n",
      "new_cols. 100\n",
      "new_cols. 0\n",
      "new_cols. 100\n",
      "new_cols. 0\n",
      "new_cols. 100\n",
      "new_cols. 0\n",
      "new_cols. 100\n",
      "new_cols. 0\n",
      "new_cols. 100\n",
      "new_cols. 0\n",
      "new_cols. 100\n",
      "new_cols. 0\n",
      "new_cols. 100\n",
      "new_cols. 0\n",
      "new_cols. 100\n",
      "new_cols. 0\n",
      "new_cols. 100\n",
      "new_cols. 0\n",
      "new_cols. 100\n",
      "new_cols. 0\n",
      "new_cols. 100\n",
      "new_cols. 0\n",
      "new_cols. 100\n",
      "new_cols. 0\n",
      "new_cols. 100\n",
      "new_cols. 0\n",
      "new_cols. 100\n",
      "new_cols. 0\n",
      "new_cols. 100\n",
      "new_cols. 0\n",
      "new_cols. 100\n",
      "new_cols. 0\n",
      "new_cols. 100\n",
      "new_cols. 0\n",
      "new_cols. 100\n",
      "new_cols. 0\n",
      "new_cols. 100\n",
      "new_cols. 0\n",
      "new_cols. 110\n",
      "new_cols. 0\n",
      "new_cols. 110\n",
      "new_cols. 0\n",
      "new_cols. 110\n",
      "new_cols. 0\n",
      "new_cols. 110\n",
      "new_cols. 0\n",
      "new_cols. 110\n",
      "new_cols. 0\n",
      "new_cols. 110\n",
      "new_cols. 0\n",
      "new_cols. 110\n",
      "new_cols. 0\n",
      "new_cols. 110\n",
      "new_cols. 0\n",
      "new_cols. 110\n",
      "new_cols. 0\n",
      "new_cols. 110\n",
      "new_cols. 0\n",
      "new_cols. 110\n",
      "new_cols. 0\n",
      "new_cols. 110\n",
      "new_cols. 0\n",
      "new_cols. 110\n",
      "new_cols. 0\n",
      "new_cols. 110\n",
      "new_cols. 0\n",
      "new_cols. 110\n",
      "new_cols. 0\n",
      "new_cols. 110\n",
      "new_cols. 0\n",
      "new_cols. 110\n",
      "new_cols. 0\n",
      "new_cols. 110\n",
      "new_cols. 0\n",
      "new_cols. 110\n",
      "new_cols. 0\n",
      "new_cols. 110\n",
      "new_cols. 0\n",
      "new_cols. 110\n",
      "new_cols. 0\n",
      "new_cols. 110\n",
      "new_cols. 0\n",
      "new_cols. 110\n",
      "new_cols. 0\n",
      "new_cols. 110\n",
      "new_cols. 0\n",
      "new_cols. 110\n",
      "new_cols. 0\n",
      "new_cols. 110\n",
      "new_cols. 0\n",
      "new_cols. 110\n",
      "new_cols. 0\n",
      "new_cols. 110\n",
      "new_cols. 0\n",
      "new_cols. 110\n",
      "new_cols. 0\n",
      "new_cols. 110\n",
      "new_cols. 0\n",
      "new_cols. 110\n",
      "new_cols. 0\n",
      "new_cols. 110\n",
      "new_cols. 0\n",
      "new_cols. 110\n",
      "new_cols. 0\n",
      "new_cols. 110\n",
      "new_cols. 0\n",
      "new_cols. 110\n",
      "new_cols. 0\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "#     spot_log_names = [\"AgentNum\", \"WaitTimeMenSmallToiletList\"] #set log names of spot that you want to make excel sheet\n",
    "    spot_log_names = [\"AgentNum\",   \"MovedNum\", \"SexList\", \"TotalRouteNumToAcceptanceList\", \"RouteCostToAcceptanceList\", \"RouteCostToAcceptanceBetweenCorridorAndCorridorList\", \"RouteCostToAcceptanceBetweenCorridorAndLivingSpaceList\", \"RouteCostToAcceptanceBetweenLivingSpaceAndLivingSpaceList\", \"TotalRouteNumToToiletList\", \"RouteCostToToiletList\", \"RouteCostToToiletBetweenCorridorAndCorridorList\", \"RouteCostToToiletBetweenCorridorAndLivingSpaceList\", \"RouteCostToToiletBetweenLivingSpaceAndLivingSpaceList\", \"WaitTimeAcceptanceList\", \"WaitTimeMenBigToiletList\", \"WaitTimeMenSmallToiletList\", \"WaitTimeWomenToiletList\"] #set log names of spot that you want to make excel sheet\n",
    "    agent_log_names = [] #set log names of agent that you want to make excel sheet\n",
    "    # set folder name you want to input data\n",
    "    input_log_directory_names = [\"10\", \"20\", \"30\", \"40\", \"50\", \"60\", \"70\", \"80\", \"90\", \"100\", \"110\"]\n",
    "    for input_log_directory_name in input_log_directory_names:\n",
    "        readLogAndWriteExcels(spot_log_names, agent_log_names, input_log_directory_name)\n",
    "    \n",
    "def readLogAndWriteExcels(spot_log_names, agent_log_names, input_log_directory_name):\n",
    "    all_log_directries = glob.glob(\"log_kagakuin/\" + input_log_directory_name + \"/*\")\n",
    "    log_dict = {}\n",
    "    for (i, log_directory) in enumerate(all_log_directries):\n",
    "        if len(spot_log_names) != 0:\n",
    "            for spot_log_name in spot_log_names:\n",
    "                if spot_log_name not in log_dict:\n",
    "                    log_dict[spot_log_name]= []\n",
    "                log_dict[spot_log_name].append(log_directory + \"/spots/\" + spot_log_name + \".log\")\n",
    "        if len(agent_log_names) != 0:\n",
    "            for agent_log_name in agent_log_names:\n",
    "                if agent_log_name not in log_dict:\n",
    "                    log_dict[agent_log_name]= []\n",
    "                log_dict[agent_log_name].append(log_directory + \"/agents/\" + agent_log_name + \".log\")\n",
    "    write_excels(log_dict, input_log_directory_name)\n",
    "    \n",
    "# [[], []]形式の場合で、全てを[2, 3, 4, 4]の形のリストに展開してから合計を算出するためのメソッド。平均は男女数に依存するのでexcelで行う\n",
    "def unfold_list(cols):\n",
    "    new_cols = []\n",
    "    for i, col in enumerate(cols):\n",
    "        if type(col) == int:\n",
    "            continue\n",
    "        if col.startswith('['):\n",
    "            last_index = find_index_of_last_element(cols, i)\n",
    "            if i is None:\n",
    "                print(\"Error on find_index_of_last_element\")\n",
    "                return\n",
    "            unfolded_list = cols[i:last_index]\n",
    "            unfolded_list[0] = unfolded_list[0].replace('[', '')\n",
    "            unfolded_list[-1] = unfolded_list[-1].replace(']', '')\n",
    "            if unfolded_list[0] == '':\n",
    "                continue\n",
    "            unfolded_list = [int(i) for i in unfolded_list]\n",
    "            new_cols+=unfolded_list\n",
    "    return new_cols\n",
    "    \n",
    "# [[], []]形式の場合、リスト内の平均を算出して返す\n",
    "def process_list_average(cols):\n",
    "    new_cols = []\n",
    "    for i, col in enumerate(cols):\n",
    "        if type(col) == int:\n",
    "            continue\n",
    "        if col.startswith('['):\n",
    "            last_index = find_index_of_last_element(cols, i)\n",
    "            if i is None:\n",
    "                print(\"Error by find_index_of_last_element\")\n",
    "                return\n",
    "            list_to_calc_average = cols[i:last_index]\n",
    "            list_to_calc_average[0] = list_to_calc_average[0].replace('[', '')\n",
    "            list_to_calc_average[-1] = list_to_calc_average[-1].replace(']', '')\n",
    "            if list_to_calc_average[0] == '':\n",
    "                continue\n",
    "            list_to_calc_average = [int(i) for i in list_to_calc_average]\n",
    "            ave = np.average(list_to_calc_average)\n",
    "            new_cols.append(ave)\n",
    "    return new_cols\n",
    "    \n",
    "def find_index_of_last_element(cols, index):\n",
    "#     i = index+1\n",
    "    cols = cols[index:]\n",
    "    for i, col in enumerate(cols):\n",
    "        if col.endswith(']'):\n",
    "            return index+i+1\n",
    "    \n",
    "def process_normal_log(col):\n",
    "    if col.startswith('['):\n",
    "        col = col[1:]\n",
    "    if col.endswith(']'):\n",
    "        col = col[:-1]\n",
    "    return col\n",
    "    \n",
    "def replace_comma(ele):\n",
    "    return ele.replace(',', '')\n",
    "    \n",
    "def write_excels(log_dict, input_log_directory_name):\n",
    "    def read_log(path):\n",
    "        log1 = codecs.open(path, mode=\"r\", encoding=\"utf-8\")\n",
    "        log2 = codecs.open(path, mode=\"r\", encoding=\"utf-8\")\n",
    "        row_num = sum(1 for row in log1)\n",
    "        for (i, row) in enumerate(log2):\n",
    "            if i+1 == row_num:\n",
    "                line = row\n",
    "        cols = line.split()\n",
    "        cols = list(map(replace_comma, cols))\n",
    "        new_cols = []\n",
    "        firstCell = cols[2]\n",
    "        \n",
    "        if firstCell.startswith('[['):\n",
    "            if os.path.basename(path).startswith('WaitTime'):\n",
    "                unfolded_list = unfold_list(cols)\n",
    "                #  合計を算出してエクセルに表記。np.sumのみのint型だとなぜかexcelに書き込む時にエラーが出るのでfloat64にキャストしてる\n",
    "                return [np.float64(np.sum(unfolded_list))]\n",
    "            return process_list_average(cols)\n",
    "        for col in cols:\n",
    "            new_col = process_normal_log(col)\n",
    "            if new_col == '':\n",
    "                continue\n",
    "            new_cols.append(new_col)\n",
    "            # エージェント数がおかしい時のロギング\n",
    "#         if os.path.basename(path).startswith('AgentNum'):\n",
    "#             for col in new_cols[2:]:\n",
    "#                 print(\"new_cols. \" + col)\n",
    "        return new_cols[2:]\n",
    "\n",
    "    book = px.Workbook()\n",
    "    for key, value_list in log_dict.items():\n",
    "        # RouteCostToToiletBetweenCorridorAndLivingSpaceList\n",
    "        key = key.replace('Between', 'B_W')\n",
    "        key = key.replace('Corridor', 'Cor')\n",
    "        key = key.replace('LivingSpace', 'LS')\n",
    "        key = key.replace('Acceptance', 'Accept')\n",
    "        sheet = book.create_sheet(title=key[:30])\n",
    "        for (i, value) in enumerate(value_list):\n",
    "            row = read_log(value)\n",
    "            row_num = i+1\n",
    "            for (i, val) in enumerate(row):\n",
    "                sheet.cell(row=row_num, column=i+1).value = val\n",
    "    book.save('kagakuin_log_' + input_log_directory_name + '.xlsx')\n",
    "    \n",
    "\n",
    "main()\n",
    "\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#  一度エクセルに整理したログデータをさらに1つのファイルに加工する\n",
    "def process_main():\n",
    "#     input_log_directory_names = [\"100\"]\n",
    "    input_log_directory_names = [\"10\", \"20\", \"30\", \"40\", \"50\", \"60\", \"70\", \"80\", \"90\", \"100\", \"110\"]\n",
    "    \n",
    "    new_wb = px.Workbook()\n",
    "    for dir_name in input_log_directory_names:\n",
    "        read_wb = px.load_workbook('kagakuin_log_' + dir_name + '.xlsx')\n",
    "        new_wb = processLog(new_wb, read_wb, dir_name)\n",
    "    sheetnames = new_wb.get_sheet_names()\n",
    "    for sheetname in sheetnames:\n",
    "        if sheetname is 'Sheet':\n",
    "            continue\n",
    "        sheet = new_wb.get_sheet_by_name(sheetname)\n",
    "        sheet = writeIndexToExcel(sheet)\n",
    "    new_wb.save('kaiseki.xlsx')\n",
    "    \n",
    "def processLog(new_wb, read_wb, dir_name):\n",
    "        tmp_wb = px.Workbook()\n",
    "        sheetnames = new_wb.get_sheet_names()\n",
    "        \n",
    "        # AgentNum\n",
    "        title = 'AgentNum'\n",
    "        read_sheet = read_wb.get_sheet_by_name(title)\n",
    "        if title in sheetnames:\n",
    "            new_sheet = new_wb.get_sheet_by_name(title)\n",
    "        else:\n",
    "            new_sheet = new_wb.create_sheet(title=title)\n",
    "        new_sheet = writeReshapeFromFirstColumnToLastRow(new_sheet, read_sheet)\n",
    "    \n",
    "        # make Invaded  Cost to toilet, routeCost - routeNum\n",
    "        tmp_read_sheet = tmp_wb.create_sheet()\n",
    "        tmp_read_sheet = subtractSheetBySheet(tmp_read_sheet, read_wb.get_sheet_by_name('RouteCostToToiletList'), read_wb.get_sheet_by_name('TotalRouteNumToToiletList'), int(dir_name))\n",
    "        title = 'ICtoToilet'\n",
    "        if title in sheetnames:\n",
    "            new_sheet = new_wb.get_sheet_by_name(title)\n",
    "        else:\n",
    "            new_sheet = new_wb.create_sheet(title=title)\n",
    "        new_sheet = writeReshapeFromFirstColumnToLastRow(new_sheet, tmp_read_sheet)\n",
    "\n",
    "        # make Invaded  Cost to acceptance, routeCost - routeNum\n",
    "        tmp_read_sheet = tmp_wb.create_sheet()\n",
    "        tmp_read_sheet = subtractSheetBySheet(tmp_read_sheet, read_wb.get_sheet_by_name('RouteCostToAcceptList'), read_wb.get_sheet_by_name('TotalRouteNumToAcceptList'), int(dir_name))\n",
    "        title = 'ICtoAcceptance'\n",
    "        if title in sheetnames:\n",
    "            new_sheet = new_wb.get_sheet_by_name(title)\n",
    "        else:\n",
    "            new_sheet = new_wb.create_sheet(title=title)\n",
    "        new_sheet = writeReshapeFromFirstColumnToLastRow(new_sheet, tmp_read_sheet)\n",
    "        \n",
    "        def calcAndWrite(title):\n",
    "            tmp_read_sheet = tmp_wb.create_sheet()\n",
    "            tmp_read_sheet = read_wb.get_sheet_by_name(title)\n",
    "            tmp_read_sheet = calcAveragePerAgent(tmp_read_sheet, read_sheet, int(dir_name))\n",
    "            if title in sheetnames:\n",
    "                new_sheet = new_wb.get_sheet_by_name(title)\n",
    "            else:\n",
    "                new_sheet = new_wb.create_sheet(title=title)\n",
    "            new_sheet = writeReshapeFromFirstColumnToLastRow(new_sheet, tmp_read_sheet)\n",
    "            \n",
    "        # calcAndWrite execute\n",
    "        calcAndWriteList = ['TotalRouteNumToAcceptList', 'RouteCostToAcceptList', 'TotalRouteNumToToiletList', 'RouteCostToToiletList']\n",
    "        for title in calcAndWriteList:\n",
    "            calcAndWrite(title)\n",
    "            \n",
    "        # 性別ごとの人数カウント。以下の形。\n",
    "        #  sexCountDict = {\n",
    "        #    10: [{man: 20, woman: 30}, {man: 20, woman: 30}],\n",
    "         #   20: [{man: 20, woman: 30}, {man: 20, woman: 30}]\n",
    "        #  }\n",
    "        title = 'SexList'\n",
    "        read_sheet = read_wb.get_sheet_by_name(title)\n",
    "        if title in sheetnames:\n",
    "            new_sheet = new_wb.get_sheet_by_name(title)\n",
    "        else:\n",
    "            new_sheet = new_wb.create_sheet(title=title)\n",
    "        sexList = countEachSex(read_sheet)\n",
    "\n",
    "        def calcAndWriteWaitTime(title, sexList, sex):\n",
    "            read_sheet = read_wb.get_sheet_by_name(title)\n",
    "            if title in sheetnames:\n",
    "                new_sheet = new_wb.get_sheet_by_name(title)\n",
    "            else:\n",
    "                new_sheet = new_wb.create_sheet(title=title)\n",
    "                new_sheet = calcWaitAverageAndWrite(new_sheet, read_sheet, sexList, sex)\n",
    "            return new_sheet\n",
    "\n",
    "        #  WaitTime\n",
    "        calcAndWriteWaitTime('WaitTimeMenBigToiletList', sexList, 'man')\n",
    "        calcAndWriteWaitTime('WaitTimeMenSmallToiletList', sexList, 'man')\n",
    "        calcAndWriteWaitTime('WaitTimeWomenToiletList', sexList, 'woman')\n",
    "            \n",
    "        return new_wb\n",
    "    \n",
    "def countEachSex(read_sheet):\n",
    "    sexList = []\n",
    "    for row in read_sheet.rows:\n",
    "        sexCount = {'man': 0, 'woman': 0}\n",
    "        for cell in row:\n",
    "            if cell.value == 'man':\n",
    "                sexCount['man'] += 1\n",
    "            elif cell.value == 'woman':\n",
    "                sexCount['woman'] += 1\n",
    "        sexList.append(sexCount)\n",
    "    return sexList\n",
    "\n",
    "# トイレの待ち時間平均を性別に応じて算出するメソッド\n",
    "def calcWaitAverageAndWrite(new_sheet, read_sheet, sexList, sex):\n",
    "    data = read_sheet.columns[0]\n",
    "    last_row = new_sheet.max_row + 1\n",
    "    for index, cell in enumerate(data):\n",
    "        waitTimeAverage = np.float64(cell.value) / np.float64(sexList[index][sex])\n",
    "        new_sheet.cell(row=last_row, column=index+2).value = waitTimeAverage\n",
    "    return new_sheet\n",
    "\n",
    "\n",
    "# 1列目を取得して、横に並べる。最終行に追加していく。\n",
    "def writeReshapeFromFirstColumnToLastRow(new_sheet, read_sheet):\n",
    "    data = read_sheet.columns[0]\n",
    "    sheet_last_row_index = new_sheet.max_row + 1\n",
    "    for index, d in enumerate(data):\n",
    "        new_sheet.cell(row=sheet_last_row_index, column=index+2).value = np.float64(d.value)\n",
    "    return new_sheet\n",
    "\n",
    "# 行、列の番号を振り、罫線をつける \n",
    "def writeIndexToExcel(new_sheet):\n",
    "    border_style = 'medium'\n",
    "    sheet_last_row_index = new_sheet.max_column\n",
    "    \n",
    "    for i in np.arange(1, sheet_last_row_index+1):\n",
    "        cell = new_sheet.cell(row=1, column=i+1)\n",
    "        cell.value = np.float64(i)\n",
    "        cell.border = Border(\n",
    "            left=Side(border_style=border_style, color='FF000000'),\n",
    "            right=Side(border_style=border_style, color='FF000000'),\n",
    "            top=Side(border_style=border_style, color='FF000000'),\n",
    "            bottom=Side(border_style=border_style, color='FF000000'),\n",
    "            diagonal=Side(border_style=border_style, color='FF000000'),\n",
    "            outline=Side(border_style=border_style, color='FF000000'),\n",
    "            vertical=Side(border_style=border_style, color='FF000000'),\n",
    "            horizontal=Side(border_style=border_style, color='FF000000')\n",
    "        )\n",
    "    for index, dir_name in enumerate(np.arange(10, 120, 10)):\n",
    "        cell = new_sheet.cell(row=index+2, column=1)\n",
    "        cell.value = str(dir_name) # TODO import from directory name\n",
    "        cell.border = Border(\n",
    "            left=Side(border_style=border_style, color='FF000000'),\n",
    "            right=Side(border_style=border_style, color='FF000000'),\n",
    "            top=Side(border_style=border_style, color='FF000000'),\n",
    "            bottom=Side(border_style=border_style, color='FF000000'),\n",
    "            diagonal=Side(border_style=border_style, color='FF000000'),\n",
    "            outline=Side(border_style=border_style, color='FF000000'),\n",
    "            vertical=Side(border_style=border_style, color='FF000000'),\n",
    "            horizontal=Side(border_style=border_style, color='FF000000')\n",
    "        )\n",
    "    return new_sheet\n",
    "\n",
    "# 第一引数側から第二引数側の、各セルの値を引いて、平均を算出して、一旦tmp_sheetの一列目に書き出し。\n",
    "def subtractSheetBySheet(new_sheet, read_sheet1, read_sheet2, agentNum):\n",
    "    for row in read_sheet1.rows:\n",
    "        subtracted_list = []\n",
    "        for cell in row:\n",
    "            cellAt = cell.column + str(cell.row)\n",
    "            subtracted_list.append(np.float64(cell.value) - np.float64(read_sheet2.cell(cellAt).value))\n",
    "        last_row = new_sheet.max_row + 1\n",
    "        new_sheet.cell(row=last_row, column=1).value = np.float64(np.sum(subtracted_list) / agentNum)\n",
    "    return new_sheet\n",
    "\n",
    "# 読み込んだシートの行ごとに平均を算出\n",
    "def calcAveragePerAgent(new_sheet, read_sheet, agentNum):\n",
    "    for row in read_sheet.rows:\n",
    "        subtracted_list = []\n",
    "        for cell in row:\n",
    "            subtracted_list.append(np.float64(cell.value))\n",
    "        last_row = new_sheet.max_row + 1\n",
    "        new_sheet.cell(row=last_row, column=1).value = np.float64(np.sum(subtracted_list) / agentNum)\n",
    "    return new_sheet\n",
    "            \n",
    "process_main()\n",
    "#     sheet.cell(row=2, column=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2])"
      ]
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(1,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 10,  20,  30,  40,  50,  60,  70,  80,  90, 100, 110])"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(10, 120, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: b'$ID'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-d8c45a008a58>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadtxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/1/spots/AgentNum.log'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/keitamiya/anaconda/lib/python3.5/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mloadtxt\u001b[0;34m(fname, dtype, comments, delimiter, converters, skiprows, usecols, unpack, ndmin)\u001b[0m\n\u001b[1;32m    926\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    927\u001b[0m             \u001b[0;31m# Convert each value according to its column and store\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 928\u001b[0;31m             \u001b[0mitems\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconverters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    929\u001b[0m             \u001b[0;31m# Then pack it according to the dtype's nesting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    930\u001b[0m             \u001b[0mitems\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpack_items\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpacking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/keitamiya/anaconda/lib/python3.5/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    926\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    927\u001b[0m             \u001b[0;31m# Convert each value according to its column and store\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 928\u001b[0;31m             \u001b[0mitems\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconverters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    929\u001b[0m             \u001b[0;31m# Then pack it according to the dtype's nesting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    930\u001b[0m             \u001b[0mitems\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpack_items\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpacking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/keitamiya/anaconda/lib/python3.5/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mfloatconv\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    657\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34mb'0x'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromhex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0masstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 659\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    660\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    661\u001b[0m     \u001b[0mtyp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: b'$ID'"
     ]
    }
   ],
   "source": [
    "np.loadtxt('data/1/spots/AgentNum.log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object read_log at 0x109574ca8>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = 'data/1/spots/AgentNum.log'\n",
    "test = []\n",
    "def read_log(path):\n",
    "    COLUMN_NUM = 6\n",
    "    with codecs.open(path, mode=\"rU\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            test.append(line)\n",
    "            columns = line.split(\"\\t\")\n",
    "            if len(columns) < COLUMN_NUM:\n",
    "                continue\n",
    "            yield columns, line.rstrip(\"\\n\")\n",
    "            print(line)\n",
    "            print(test)\n",
    "read_log(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = codecs.open(path, mode=\"rU\", encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<codecs.StreamReaderWriter at 0x10957d390>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = 'data/1/agents/Sex.log'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = codecs.open(path, mode=\"r\", encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bb = codecs.StreamReader(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['woman', 'woman', 'man', 'man', 'man', 'woman', 'woman', 'woman', 'man', 'woman', 'woman', 'man', 'woman', 'woman', 'man', 'man', 'woman', 'woman', 'woman', 'woman', 'woman', 'man', 'woman', 'woman', 'man', 'man', 'woman', 'man', 'man', 'woman', 'woman', 'man', 'woman', 'woman', 'woman', 'woman', 'man', 'woman', 'man', 'woman', 'woman', 'woman', 'woman', 'woman', 'woman', 'woman', 'woman', 'man', 'woman', 'man', 'man', 'woman', 'man', 'man', 'woman', 'woman', 'woman', 'man', 'man', 'woman', 'man', 'man', 'man', 'woman', 'woman', 'woman', 'woman', 'man', 'man', 'woman', 'woman', 'man', 'man', 'man', 'woman', 'man', 'man', 'woman', 'man', 'man', 'woman', 'woman', 'woman', 'man', 'woman', 'woman', 'man', 'man', 'man', 'man', 'woman', 'man', 'woman', 'man', 'woman', 'woman', 'woman', 'man', 'man', 'man', 'man', 'man', 'man', 'woman', 'man', 'woman', 'woman', 'woman', 'woman', 'man', 'man', 'woman', 'woman', 'man', 'woman', 'woman', 'man', 'man', 'woman', 'woman', 'woman', 'man', 'man', 'woman', 'woman']\n"
     ]
    }
   ],
   "source": [
    "a = codecs.open(path, mode=\"r\", encoding=\"utf-8\")\n",
    "b = codecs.open(path, mode=\"r\", encoding=\"utf-8\")\n",
    "tete = sum(1 for row in a)\n",
    "for (i, row) in enumerate(b):\n",
    "    if i+1 == tete:\n",
    "        line = row\n",
    "cols = line.split()\n",
    "# cols.replace(\"\\n\", \"\")\n",
    "print(cols[2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hoge hoge\n"
     ]
    }
   ],
   "source": [
    "src = \"{hoge hoge}\"\n",
    "dst = src.replace('{', '').replace('}', '')\n",
    "print(dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[aaa']"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tete = [\"aa\", \"[aaa\", \"aaaaadddd\", \"afsdfa]\"]\n",
    "aaa = tete[1:2]\n",
    "tete\n",
    "aaa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aa', 'aaa', 'aaaaadddd', 'afsdfa]']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tete[1] = tete[1].replace('[', '')\n",
    "tete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "for val, index in enumerate(tete):\n",
    "    print(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'TotalRouteNumToToiletList.log'"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.basename('data/3/spots/TotalRouteNumToToiletList.log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = []\n",
    "test.extend([222, 333])\n",
    "test.extend([222, 333])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[222, 333, 222, 333]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'12345'"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aiueo = '123456aaaaaaaaaaaaaaaaaaaaaaaaa'\n",
    "aiueo[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.float64(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.int64"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(np.sum([1,4,5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'numpy' has no attribute 'range'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-235-b9379318b326>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: module 'numpy' has no attribute 'range'"
     ]
    }
   ],
   "source": [
    "np.range(100,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = 0\n",
    "test += 1\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'append'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-401-830ce1aacb0d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m21\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'append'"
     ]
    }
   ],
   "source": [
    "test = np.array([])\n",
    "test.append([6, 9, 21])\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
